{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:04.396450Z",
     "start_time": "2025-05-22T14:23:00.999870Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.load_results import *\n",
    "from utils.plot_helpers import *\n",
    "from utils.analysis_from_interaction import *\n",
    "from utils.concept_reps import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather dataframes for analysis of pragmatic mechanisms\n",
    "This notebook is used to gather data from the different conditions and save them as csv files that can be used for a Bayesian analysis in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:04.399148Z",
     "start_time": "2025-05-22T14:23:04.396280Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ['(3,4)', '(3,8)', '(3,16)', '(4,4)', '(4,8)', '(5,4)']\n",
    "n_values = [4, 8, 16, 4, 8, 4]\n",
    "n_attributes = [3, 3, 3, 4, 4, 5]\n",
    "vocab_sizes = [5, 9, 17, 5, 9, 5]\n",
    "n_epochs = 300\n",
    "n_runs = 5\n",
    "n_datasets = len(datasets)\n",
    "paths = ['results/' + d + '_game_size_10_vsf_0' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "length_cost = True # whether length_cost was applied\n",
    "early_stopping = True\n",
    "sampled_context = False # actually true, but this would navigate to a different folder\n",
    "hierarchical = False\n",
    "shared_context = True\n",
    "test_interactions = False # whether scores should be calculated on test interactions\n",
    "test_mode = 'test'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:04.845739Z",
     "start_time": "2025-05-22T14:23:04.841955Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:07.002737Z",
     "start_time": "2025-05-22T14:23:06.988863Z"
    }
   },
   "outputs": [],
   "source": [
    "setting_1 = 'length_cost/context_unaware/shared_context'\n",
    "setting_2 = 'length_cost/context_aware/shared_context'\n",
    "settings = [setting_1, setting_2]\n",
    "condition_1 = 'context_unaware'\n",
    "condition_2 = 'context_aware'\n",
    "conditions = [condition_1, condition_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get n_epochs if early stopping\n",
    "n_epochs_all_data = {}\n",
    "for i, setting in enumerate(settings):\n",
    "    n_epochs_all_data[conditions[i]] = []\n",
    "    for d in range(len(datasets)):\n",
    "        \n",
    "        epochs = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "    \n",
    "            path_to_run = paths[d] + '/' + setting +'/' + str(run) + '/' \n",
    "            with open(os.path.join(path_to_run, 'loss_and_metrics.pkl'), 'rb') as input_file:\n",
    "                data = pickle.load(input_file)\n",
    "                final_epoch = max(data['loss_train'].keys())\n",
    "                epochs.append(final_epoch)\n",
    "                \n",
    "        n_epochs_all_data[conditions[i]].append(epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:07.777867Z",
     "start_time": "2025-05-22T14:23:07.751009Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "          condition  dataset  run  epoch\n0   context_unaware        0    0     69\n1   context_unaware        0    1     63\n2   context_unaware        0    2     60\n3   context_unaware        0    3     62\n4   context_unaware        0    4     52\n5   context_unaware        1    0     56\n6   context_unaware        1    1     62\n7   context_unaware        1    2     69\n8   context_unaware        1    3     63\n9   context_unaware        1    4     74\n10  context_unaware        2    0     49\n11  context_unaware        2    1     73\n12  context_unaware        2    2     61\n13  context_unaware        2    3     61\n14  context_unaware        2    4     77\n15  context_unaware        3    0     49\n16  context_unaware        3    1     44\n17  context_unaware        3    2     58\n18  context_unaware        3    3     76\n19  context_unaware        3    4     49\n20  context_unaware        4    0     37\n21  context_unaware        4    1     51\n22  context_unaware        4    2     65\n23  context_unaware        4    3     26\n24  context_unaware        4    4     41\n25  context_unaware        5    0     34\n26  context_unaware        5    1     29\n27  context_unaware        5    2     38\n28  context_unaware        5    3     33\n29  context_unaware        5    4     18\n30    context_aware        0    0     37\n31    context_aware        0    1     48\n32    context_aware        0    2     49\n33    context_aware        0    3     38\n34    context_aware        0    4     41\n35    context_aware        1    0     47\n36    context_aware        1    1     46\n37    context_aware        1    2     75\n38    context_aware        1    3     52\n39    context_aware        1    4     58\n40    context_aware        2    0     46\n41    context_aware        2    1     41\n42    context_aware        2    2    169\n43    context_aware        2    3     65\n44    context_aware        2    4     44\n45    context_aware        3    0     36\n46    context_aware        3    1     53\n47    context_aware        3    2     35\n48    context_aware        3    3     56\n49    context_aware        3    4     49\n50    context_aware        4    0     44\n51    context_aware        4    1     45\n52    context_aware        4    2     31\n53    context_aware        4    3     56\n54    context_aware        4    4    136\n55    context_aware        5    0     30\n56    context_aware        5    1     34\n57    context_aware        5    2     48\n58    context_aware        5    3     26\n59    context_aware        5    4     51",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>0</td>\n      <td>1</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>0</td>\n      <td>2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>0</td>\n      <td>3</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>0</td>\n      <td>4</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>context_unaware</td>\n      <td>1</td>\n      <td>0</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>context_unaware</td>\n      <td>1</td>\n      <td>1</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>context_unaware</td>\n      <td>1</td>\n      <td>2</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>context_unaware</td>\n      <td>1</td>\n      <td>3</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>context_unaware</td>\n      <td>1</td>\n      <td>4</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>context_unaware</td>\n      <td>2</td>\n      <td>0</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>context_unaware</td>\n      <td>2</td>\n      <td>1</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>context_unaware</td>\n      <td>2</td>\n      <td>2</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>context_unaware</td>\n      <td>2</td>\n      <td>3</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>context_unaware</td>\n      <td>2</td>\n      <td>4</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>context_unaware</td>\n      <td>3</td>\n      <td>0</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>context_unaware</td>\n      <td>3</td>\n      <td>1</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>context_unaware</td>\n      <td>3</td>\n      <td>2</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>context_unaware</td>\n      <td>3</td>\n      <td>3</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>context_unaware</td>\n      <td>3</td>\n      <td>4</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>context_unaware</td>\n      <td>4</td>\n      <td>0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>context_unaware</td>\n      <td>4</td>\n      <td>1</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>context_unaware</td>\n      <td>4</td>\n      <td>2</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>context_unaware</td>\n      <td>4</td>\n      <td>3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>context_unaware</td>\n      <td>4</td>\n      <td>4</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>context_unaware</td>\n      <td>5</td>\n      <td>0</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>context_unaware</td>\n      <td>5</td>\n      <td>1</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>context_unaware</td>\n      <td>5</td>\n      <td>2</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>context_unaware</td>\n      <td>5</td>\n      <td>3</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>context_unaware</td>\n      <td>5</td>\n      <td>4</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>context_aware</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>context_aware</td>\n      <td>0</td>\n      <td>1</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>context_aware</td>\n      <td>0</td>\n      <td>2</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>context_aware</td>\n      <td>0</td>\n      <td>3</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>context_aware</td>\n      <td>0</td>\n      <td>4</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>context_aware</td>\n      <td>1</td>\n      <td>0</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>context_aware</td>\n      <td>1</td>\n      <td>1</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>context_aware</td>\n      <td>1</td>\n      <td>2</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>context_aware</td>\n      <td>1</td>\n      <td>3</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>context_aware</td>\n      <td>1</td>\n      <td>4</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>context_aware</td>\n      <td>2</td>\n      <td>0</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>context_aware</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>context_aware</td>\n      <td>2</td>\n      <td>2</td>\n      <td>169</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>context_aware</td>\n      <td>2</td>\n      <td>3</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>context_aware</td>\n      <td>2</td>\n      <td>4</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>context_aware</td>\n      <td>3</td>\n      <td>0</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>context_aware</td>\n      <td>3</td>\n      <td>1</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>context_aware</td>\n      <td>3</td>\n      <td>2</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>context_aware</td>\n      <td>3</td>\n      <td>3</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>context_aware</td>\n      <td>3</td>\n      <td>4</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>context_aware</td>\n      <td>4</td>\n      <td>0</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>context_aware</td>\n      <td>4</td>\n      <td>1</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>context_aware</td>\n      <td>4</td>\n      <td>2</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>context_aware</td>\n      <td>4</td>\n      <td>3</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>context_aware</td>\n      <td>4</td>\n      <td>4</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>context_aware</td>\n      <td>5</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>context_aware</td>\n      <td>5</td>\n      <td>1</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>context_aware</td>\n      <td>5</td>\n      <td>2</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>context_aware</td>\n      <td>5</td>\n      <td>3</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>context_aware</td>\n      <td>5</td>\n      <td>4</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather epochs\n",
    "epochs_training = {\"condition\": [], \"dataset\": [], \"run\": [], \"epoch\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            epochs_training['condition'].append(conditions[i])\n",
    "            epochs_training['dataset'].append(d)\n",
    "            epochs_training['run'].append(run)\n",
    "            epochs_training['epoch'].append(n_epochs_all_data[conditions[i]][d][run])\n",
    "df = pd.DataFrame(epochs_training)\n",
    "df.to_csv(\"BayesianAnalysis/exp1/epochs_training.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T13:13:42.135522Z",
     "start_time": "2025-05-20T13:13:41.892027Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "test_interactions = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:29:14.716023Z",
     "start_time": "2025-05-20T12:29:14.693599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:13:32.973263Z",
     "start_time": "2025-05-20T13:13:32.541801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/pragmatic-mechanisms/utils/load_results.py:538: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result_dict[key] = np.array(result_dict[key])\n"
     ]
    },
    {
     "data": {
      "text/plain": "           condition acc_type dataset  run  accuracy\n0    context_unaware    train   (3,4)    0  0.960583\n1    context_unaware      val   (3,4)    0  0.898021\n2    context_unaware     test   (3,4)    0  0.808327\n3    context_unaware    train   (3,4)    1  0.990464\n4    context_unaware      val   (3,4)    1  0.935794\n..               ...      ...     ...  ...       ...\n175    context_aware      val   (5,4)    3  0.990262\n176    context_aware     test   (5,4)    3  0.989809\n177    context_aware    train   (5,4)    4  0.977849\n178    context_aware      val   (5,4)    4  0.965690\n179    context_aware     test   (5,4)    4  0.964370\n\n[180 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>acc_type</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>train</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.960583</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>val</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.898021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.808327</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>train</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.990464</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>val</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.935794</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>context_aware</td>\n      <td>val</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.990262</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.989809</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>context_aware</td>\n      <td>train</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.977849</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>context_aware</td>\n      <td>val</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.965690</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.964370</td>\n    </tr>\n  </tbody>\n</table>\n<p>180 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather final accuracies\n",
    "accuracies = {\"condition\": [], \"acc_type\": [], \"dataset\": [], \"run\": [], \"accuracy\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if conditions[i] == 'context_unaware':\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    all_accuracies = load_accuracies(paths, n_runs=n_runs, n_epochs=300, val_steps=1, zero_shot=False, context_unaware=context_unaware, length_cost=length_cost, early_stopping=early_stopping, sampled_context=sampled_context, hierarchical=hierarchical, shared_context=shared_context)\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for acc_type in ['train', 'val', 'test']:\n",
    "                accuracies['condition'].append(conditions[i])\n",
    "                accuracies['dataset'].append(dataset)\n",
    "                accuracies['run'].append(run)\n",
    "                accuracies['acc_type'].append(acc_type)\n",
    "                if conditions[i] == 'context_unaware':\n",
    "                    if acc_type == 'train':\n",
    "                        accuracies['accuracy'].append(all_accuracies['cu_train_acc'][d][run][-1])\n",
    "                    elif acc_type == 'val':\n",
    "                        accuracies['accuracy'].append(all_accuracies['cu_val_acc'][d][run][-1])\n",
    "                    else:\n",
    "                        accuracies['accuracy'].append(all_accuracies['cu_test_acc'][d][run])\n",
    "                else:\n",
    "                    if acc_type == 'train':\n",
    "                        accuracies['accuracy'].append(all_accuracies['train_acc'][d][run][-1])\n",
    "                    elif acc_type == 'val':\n",
    "                        accuracies['accuracy'].append(all_accuracies['val_acc'][d][run][-1])\n",
    "                    else:\n",
    "                        accuracies['accuracy'].append(all_accuracies['test_acc'][d][run])\n",
    "df = pd.DataFrame(accuracies)\n",
    "df.to_csv(\"BayesianAnalysis/exp1/accuracies.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Message length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "           condition dataset  run  fixed     ml\n0    context_unaware   (3,4)    0      0  4.443\n1    context_unaware   (3,4)    0      1  4.236\n2    context_unaware   (3,4)    0      2  3.828\n3    context_unaware   (3,4)    0      3    NaN\n4    context_unaware   (3,4)    0      4    NaN\n..               ...     ...  ...    ...    ...\n295    context_aware   (5,4)    4      0  4.434\n296    context_aware   (5,4)    4      1  4.314\n297    context_aware   (5,4)    4      2  4.304\n298    context_aware   (5,4)    4      3  4.316\n299    context_aware   (5,4)    4      4  4.316\n\n[300 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>fixed</th>\n      <th>ml</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.443</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3.828</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>context_aware</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4.434</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>context_aware</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4.314</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>context_aware</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>2</td>\n      <td>4.304</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>context_aware</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4.316</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>context_aware</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4.316</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather message lengths\n",
    "ml = {\"condition\": [], \"dataset\": [], \"run\": [], \"fixed\": [], \"ml\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            ml_hierarchical = pickle.load(open(paths[d] + '/' + setting + '/' + str(run) + \n",
    "                                           '/message_length_hierarchical.pkl', 'rb'))\n",
    "            for level in range(5):\n",
    "                ml['condition'].append(conditions[i])\n",
    "                ml['dataset'].append(dataset)\n",
    "                ml['run'].append(run)\n",
    "                ml['fixed'].append(level)\n",
    "                try: \n",
    "                    ml['ml'].append(ml_hierarchical[level])\n",
    "                except: \n",
    "                    ml['ml'].append(np.NaN)\n",
    "df = pd.DataFrame(ml)\n",
    "df.to_csv(\"BayesianAnalysis/exp1/message_length.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T13:13:35.087980Z",
     "start_time": "2025-05-20T13:13:35.071714Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/pragmatic-mechanisms/utils/load_results.py:654: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result_dict[key] = np.array(result_dict[key])\n"
     ]
    },
    {
     "data": {
      "text/plain": "           condition          score dataset  run   entropy\n0    context_unaware            NMI   (3,4)    0  0.790290\n1    context_unaware  effectiveness   (3,4)    0  0.814826\n2    context_unaware    consistency   (3,4)    0  0.767188\n3    context_unaware            NMI   (3,4)    1  0.831046\n4    context_unaware  effectiveness   (3,4)    1  0.963844\n..               ...            ...     ...  ...       ...\n175    context_aware  effectiveness   (5,4)    3  0.405036\n176    context_aware    consistency   (5,4)    3  0.686200\n177    context_aware            NMI   (5,4)    4  0.525295\n178    context_aware  effectiveness   (5,4)    4  0.423973\n179    context_aware    consistency   (5,4)    4  0.690252\n\n[180 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>score</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>NMI</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.790290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>effectiveness</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.814826</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>consistency</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.767188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>NMI</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.831046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>effectiveness</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.963844</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>context_aware</td>\n      <td>effectiveness</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.405036</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>context_aware</td>\n      <td>consistency</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.686200</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>context_aware</td>\n      <td>NMI</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.525295</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>context_aware</td>\n      <td>effectiveness</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.423973</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>context_aware</td>\n      <td>consistency</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.690252</td>\n    </tr>\n  </tbody>\n</table>\n<p>180 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather entropy scores (means)\n",
    "entropies = {\"condition\": [], \"score\": [], \"dataset\": [], \"run\": [], \"entropy\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if conditions[i] == 'context_unaware':\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    entropy_scores = load_entropies(paths, context_unaware=context_unaware, length_cost=length_cost, sampled_context=sampled_context, test_interactions=test_interactions, test_mode=test_mode, hierarchical=hierarchical, shared_context=shared_context, verbose=False)\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for score in ['NMI', 'effectiveness', 'consistency']:\n",
    "                entropies['condition'].append(conditions[i])\n",
    "                entropies['dataset'].append(dataset)\n",
    "                entropies['run'].append(run)\n",
    "                entropies['score'].append(score)\n",
    "                entropies['entropy'].append(entropy_scores[score][d][run])\n",
    "df = pd.DataFrame(entropies)\n",
    "df.to_csv(\"BayesianAnalysis/exp1/entropies.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T13:21:18.562451Z",
     "start_time": "2025-05-20T13:21:18.334508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/pragmatic-mechanisms/utils/load_results.py:654: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result_dict[key] = np.array(result_dict[key])\n"
     ]
    },
    {
     "data": {
      "text/plain": "           condition                     score dataset  run  fixed   entropy\n0    context_unaware          NMI_hierarchical   (3,4)    0      0  0.779790\n1    context_unaware          NMI_hierarchical   (3,4)    0      1  0.798455\n2    context_unaware          NMI_hierarchical   (3,4)    0      2  0.831628\n3    context_unaware          NMI_hierarchical   (3,4)    0      3       NaN\n4    context_unaware          NMI_hierarchical   (3,4)    0      4       NaN\n..               ...                       ...     ...  ...    ...       ...\n895    context_aware  consistency_hierarchical   (5,4)    4      0  0.764021\n896    context_aware  consistency_hierarchical   (5,4)    4      1  0.725995\n897    context_aware  consistency_hierarchical   (5,4)    4      2  0.699520\n898    context_aware  consistency_hierarchical   (5,4)    4      3  0.682845\n899    context_aware  consistency_hierarchical   (5,4)    4      4  0.670341\n\n[900 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>score</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>fixed</th>\n      <th>entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>NMI_hierarchical</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.779790</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>NMI_hierarchical</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.798455</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>NMI_hierarchical</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.831628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>NMI_hierarchical</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>NMI_hierarchical</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>context_aware</td>\n      <td>consistency_hierarchical</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.764021</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>context_aware</td>\n      <td>consistency_hierarchical</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.725995</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>context_aware</td>\n      <td>consistency_hierarchical</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0.699520</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>context_aware</td>\n      <td>consistency_hierarchical</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0.682845</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>context_aware</td>\n      <td>consistency_hierarchical</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.670341</td>\n    </tr>\n  </tbody>\n</table>\n<p>900 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather entropy scores (hierarchical)\n",
    "entropies = {\"condition\": [], \"score\": [], \"dataset\": [], \"run\": [], \"fixed\": [], \"entropy\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if conditions[i] == 'context_unaware':\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    entropy_scores = load_entropies(paths, context_unaware=context_unaware, length_cost=length_cost, sampled_context=sampled_context, test_interactions=test_interactions, test_mode=test_mode, hierarchical=hierarchical, shared_context=shared_context, verbose=False)\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for score in ['NMI_hierarchical', 'effectiveness_hierarchical', 'consistency_hierarchical']:\n",
    "                for level in range(5):\n",
    "                    entropies['condition'].append(conditions[i])\n",
    "                    entropies['dataset'].append(dataset)\n",
    "                    entropies['run'].append(run)\n",
    "                    entropies['score'].append(score)\n",
    "                    entropies['fixed'].append(level)\n",
    "                    try:\n",
    "                        entropies['entropy'].append(entropy_scores[score][d][run][level])\n",
    "                    except:\n",
    "                        entropies['entropy'].append(np.NaN)\n",
    "df = pd.DataFrame(entropies)\n",
    "df.to_csv(\"BayesianAnalysis/exp1/entropies_hierarchical.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T13:38:43.584368Z",
     "start_time": "2025-05-20T13:38:43.320776Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_interactions = True # whether scores should be calculated on test interactions\n",
    "test_mode = 'test'\n",
    "rsa = True\n",
    "rsa_test = 'testtrainmixed'\n",
    "rsa_test_int = 'testtrainmixed'\n",
    "condition_1 = 'context_unaware'\n",
    "condition_2 = 'context_unaware_RSA'\n",
    "condition_3 = 'context_aware'\n",
    "condition_4 = 'context_aware_RSA'\n",
    "conditions = [condition_1, condition_2, condition_3, condition_4]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:23:12.594687Z",
     "start_time": "2025-05-22T14:23:12.580700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "           condition   rsa dataset  run  accuracy\n0    context_unaware  test   (3,4)    0  0.801331\n1    context_unaware   rsa   (3,4)    0  0.822188\n2    context_unaware  test   (3,4)    1  0.818013\n3    context_unaware   rsa   (3,4)    1  0.938505\n4    context_unaware  test   (3,4)    2  0.765759\n..               ...   ...     ...  ...       ...\n115    context_aware   rsa   (5,4)    2  0.982950\n116    context_aware  test   (5,4)    3  0.999955\n117    context_aware   rsa   (5,4)    3  0.996160\n118    context_aware  test   (5,4)    4  0.973550\n119    context_aware   rsa   (5,4)    4  0.922930\n\n[120 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>rsa</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.801331</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>rsa</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0.822188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.818013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>rsa</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>0.938505</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>2</td>\n      <td>0.765759</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>2</td>\n      <td>0.982950</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.999955</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>0.996160</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.973550</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0.922930</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather final accuracies\n",
    "accuracies = {\"condition\": [], \"rsa\": [], \"dataset\": [], \"run\": [], \"accuracy\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if 'context_unaware' in setting:\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    all_accuracies = load_accuracies(paths, n_runs=n_runs, n_epochs=0, val_steps=1, zero_shot=False, context_unaware=context_unaware, length_cost=length_cost, early_stopping=early_stopping, hierarchical=hierarchical, shared_context=shared_context, rsa=rsa, rsa_test='test')\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for acc_type in ['test', 'rsa']:\n",
    "                accuracies['condition'].append(conditions[::2][i])\n",
    "                accuracies['dataset'].append(dataset)\n",
    "                accuracies['run'].append(run)\n",
    "                accuracies['rsa'].append(acc_type)\n",
    "                if acc_type == 'test':\n",
    "                    accuracies['accuracy'].append(all_accuracies['final_test_acc'][d][run])\n",
    "                else:\n",
    "                    accuracies['accuracy'].append(all_accuracies['rsa_test_acc'][d][run])\n",
    "df = pd.DataFrame(accuracies)\n",
    "df.to_csv(\"BayesianAnalysis/exp2/accuracies.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T07:32:31.476014Z",
     "start_time": "2025-05-23T07:32:31.451461Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Message length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "           condition   rsa dataset  run  fixed     ml\n0    context_unaware  test   (3,4)    0      0  3.650\n1    context_unaware  test   (3,4)    0      1  4.100\n2    context_unaware  test   (3,4)    0      2  5.688\n3    context_unaware  test   (3,4)    0      3    NaN\n4    context_unaware  test   (3,4)    0      4    NaN\n..               ...   ...     ...  ...    ...    ...\n595    context_aware   rsa   (5,4)    4      0    NaN\n596    context_aware   rsa   (5,4)    4      1    NaN\n597    context_aware   rsa   (5,4)    4      2  3.225\n598    context_aware   rsa   (5,4)    4      3  2.900\n599    context_aware   rsa   (5,4)    4      4  3.550\n\n[600 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>rsa</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>fixed</th>\n      <th>ml</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4.100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5.688</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3.225</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.900</td>\n    </tr>\n    <tr>\n      <th>599</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3.550</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather message lengths\n",
    "ml = {\"condition\": [], \"rsa\": [], \"dataset\": [], \"run\": [], \"fixed\": [], \"ml\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if 'context_unaware' in setting:\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for rsa in ['test', 'rsa']:\n",
    "                if rsa == 'test':\n",
    "                    ml_hierarchical = pickle.load(open(paths[d] + '/' + setting + '/' + str(run) + \n",
    "                                           '/message_length_hierarchical_' + test_mode + '.pkl', 'rb'))\n",
    "                else:\n",
    "                    ml_hierarchical = pickle.load(open(paths[d] + '/' + setting + '/' + str(run) + \n",
    "                                               '/message_length_hierarchical' + '_rsa_' + rsa_test_int + '.pkl', 'rb'))\n",
    "                for level in range(5):\n",
    "                    ml['condition'].append(conditions[::2][i])\n",
    "                    ml['dataset'].append(dataset)\n",
    "                    ml['run'].append(run)\n",
    "                    ml['rsa'].append(rsa)\n",
    "                    ml['fixed'].append(level)\n",
    "                    try:\n",
    "                        ml['ml'].append(ml_hierarchical[level])\n",
    "                    except:\n",
    "                        ml['ml'].append(np.NaN)\n",
    "df = pd.DataFrame(ml)\n",
    "df.to_csv(\"BayesianAnalysis/exp2/message_length.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T07:17:45.213247Z",
     "start_time": "2025-05-23T07:17:45.168733Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lexicon size and informativeness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "           condition   rsa dataset  run  lexsize   lexinfo\n0    context_unaware  test   (3,4)    0       97  6.323225\n1    context_unaware   rsa   (3,4)    0       58  3.783062\n2    context_unaware  test   (3,4)    1      104  3.409091\n3    context_unaware   rsa   (3,4)    1       52  4.388824\n4    context_unaware  test   (3,4)    2      102  6.770833\n..               ...   ...     ...  ...      ...       ...\n115    context_aware   rsa   (5,4)    2       50  4.044269\n116    context_aware  test   (5,4)    3       87  3.210536\n117    context_aware   rsa   (5,4)    3       56  3.326627\n118    context_aware  test   (5,4)    4       81  4.373396\n119    context_aware   rsa   (5,4)    4       55  2.797478\n\n[120 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>condition</th>\n      <th>rsa</th>\n      <th>dataset</th>\n      <th>run</th>\n      <th>lexsize</th>\n      <th>lexinfo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>97</td>\n      <td>6.323225</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>context_unaware</td>\n      <td>rsa</td>\n      <td>(3,4)</td>\n      <td>0</td>\n      <td>58</td>\n      <td>3.783062</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>104</td>\n      <td>3.409091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>context_unaware</td>\n      <td>rsa</td>\n      <td>(3,4)</td>\n      <td>1</td>\n      <td>52</td>\n      <td>4.388824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>context_unaware</td>\n      <td>test</td>\n      <td>(3,4)</td>\n      <td>2</td>\n      <td>102</td>\n      <td>6.770833</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>2</td>\n      <td>50</td>\n      <td>4.044269</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>87</td>\n      <td>3.210536</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>3</td>\n      <td>56</td>\n      <td>3.326627</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>context_aware</td>\n      <td>test</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>81</td>\n      <td>4.373396</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>context_aware</td>\n      <td>rsa</td>\n      <td>(5,4)</td>\n      <td>4</td>\n      <td>55</td>\n      <td>2.797478</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather lexicon sizes\n",
    "distance = 'manhattan'\n",
    "lex = {\"condition\": [], \"rsa\": [], \"dataset\": [], \"run\": [], \"lexsize\": [], \"lexinfo\": []}\n",
    "for i, setting in enumerate(settings):\n",
    "    if 'context_unaware' in setting:\n",
    "        context_unaware = True\n",
    "    else:\n",
    "        context_unaware = False\n",
    "    for d, dataset in enumerate(datasets):\n",
    "        for run in range(n_runs):\n",
    "            for rsa in ['test', 'rsa']:\n",
    "                if rsa == 'test':\n",
    "                    lexprops = pickle.load(open(paths[d] + '/' + setting + '/' + str(run) + \n",
    "                                           '/lexicon_properties_' + distance + '_' + test_mode + '.pkl', 'rb'))\n",
    "                else:\n",
    "                    lexprops = pickle.load(open(paths[d] + '/' + setting + '/' + str(run) + \n",
    "                                           '/lexicon_properties_' + distance + '_rsa_' + rsa_test_int + '.pkl', 'rb'))\n",
    "                lex['condition'].append(conditions[::2][i])\n",
    "                lex['dataset'].append(dataset)\n",
    "                lex['run'].append(run)\n",
    "                lex['rsa'].append(rsa)\n",
    "                lex['lexsize'].append(lexprops['lexicon size'])\n",
    "                lex['lexinfo'].append(lexprops['lexicon informativeness'])\n",
    "df = pd.DataFrame(lex)\n",
    "df.to_csv(\"BayesianAnalysis/exp2/lexicon_props.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T07:17:54.338618Z",
     "start_time": "2025-05-23T07:17:54.298436Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "egg",
   "language": "python",
   "display_name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "33315512203c6451c0a69878c82cfb8f373990930a82d73b6ace859088458855"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
